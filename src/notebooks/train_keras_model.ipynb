{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from __future__ import print_function\n",
    "\n",
    "DEPRECATED_HOME = '/root'\n",
    "\n",
    "PROJECT_DIR = '~/shared/Documents/final_proj'\n",
    "PROJECT_DIR = os.path.expanduser(PROJECT_DIR)\n",
    "\n",
    "BASE_MODELS_DIR = os.path.join(PROJECT_DIR, 'models/trained_models')\n",
    "ATTR_MODELS_DIR = os.path.join(BASE_MODELS_DIR, 'attribute_models')\n",
    "BASE_FEATURES_DIR = os.path.join(PROJECT_DIR, 'extracted_features')\n",
    "SVM_MODELS_DIR = os.path.join(PROJECT_DIR, 'models/svm_models')\n",
    "SPLITS_DIR = os.path.join(PROJECT_DIR,'datasets/splits/annotator_consistency3')\n",
    "STATS_MODELS_DIR = os.path.join(SVM_MODELS_DIR, 'stats')\n",
    "LOGS_DIR = os.path.join(PROJECT_DIR, 'logs')\n",
    "\n",
    "ARCH = 'mobileNet'\n",
    "LAYER = 'fc7'\n",
    "\n",
    "DOMAIN='domain'\n",
    "RELATION='relation'\n",
    "DATA_TYPE=DOMAIN\n",
    "\n",
    "CONFIG = LAYER + '_' + DATA_TYPE + '_' + ARCH\n",
    "\n",
    "DOMAIN_CLASSES, RELATION_CLASSES = 5, 16\n",
    "\n",
    "if DATA_TYPE == DOMAIN:\n",
    "    N_CLASSES = DOMAIN_CLASSES\n",
    "    labels_path = os.path.join(SPLITS_DIR,'domain_single_body1_{}_5.txt')\n",
    "else:\n",
    "    N_CLASSES = RELATION_CLASSES\n",
    "    labels_path = os.path.join(SPLITS_DIR,'single_body1_{}_16.txt')    \n",
    "\n",
    "LABELS = [str(label) for label in range(N_CLASSES)]    \n",
    "\n",
    "end2end_model = True\n",
    "\n",
    "if end2end_model:\n",
    "    FEATURES_DIR = os.path.join(BASE_FEATURES_DIR, 'end_to_end_features', CONFIG)    \n",
    "else:    \n",
    "    FEATURES_DIR = os.path.join(BASE_FEATURES_DIR, 'attribute_features', CONFIG)\n",
    "\n",
    "stored_features_dir = os.path.join(FEATURES_DIR, 'all_splits_numpy_format')\n",
    "\n",
    "N_STREAMS = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "KERAS_TO_CAFFE_SPLITS = {'train': 'train', 'test': 'eval', 'val': 'test'}\n",
    "FILE_FORMAT = '{}single_body'.format('domain_' if DATA_TYPE == DOMAIN else \"\") \\\n",
    "            + '{input_idx}_{split}_' + str(N_CLASSES) + '.txt'\n",
    "\n",
    "STREAM_IDS = [str(idx) for idx in [1, 2]]\n",
    "\n",
    "def process_line(line):\n",
    "    image_path, label = line.strip().split(' ')\n",
    "    image_path = image_path.replace(DEPRECATED_HOME, '~')\n",
    "\n",
    "    if '~' in image_path:\n",
    "        image_path = os.path.expanduser(image_path)\n",
    "\n",
    "    return image_path, label\n",
    "\n",
    "def get_file_name(split, input_idx, f_pattern=FILE_FORMAT):\n",
    "    return f_pattern.format(split=KERAS_TO_CAFFE_SPLITS[split],\n",
    "                            input_idx=input_idx)\n",
    "\n",
    "def get_split_mapping(files_dir, splits, input_indices, f_pattern=FILE_FORMAT):\n",
    "    mapping = {}\n",
    "    for split in splits:\n",
    "        for input_idx in input_indices:\n",
    "            key = os.path.join(split, input_idx)\n",
    "            value =  os.path.join(files_dir, get_file_name(split, input_idx, f_pattern))\n",
    "            mapping[key] = value\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "def create_fake_directory(root_dir, split_mapping, labels, process_line_cb):\n",
    "    if not os.path.exists(root_dir):\n",
    "        os.mkdir(root_dir)\n",
    "    \n",
    "    for images_dir, images_file in split_mapping.items():\n",
    "        abs_images_dir = os.path.join(root_dir, images_dir)\n",
    "        \n",
    "        for label in labels:\n",
    "            label_dir = os.path.join(abs_images_dir, label)\n",
    "            if not os.path.exists(label_dir):\n",
    "                os.makedirs(label_dir)\n",
    "\n",
    "        abs_images_file = os.path.join(abs_images_dir, images_file)\n",
    "        with open(abs_images_file) as f:\n",
    "            for fake_id, line in enumerate(f):\n",
    "                image_path, label = process_line_cb(line)\n",
    "                fake_name = '{}{}'.format(fake_id, os.path.splitext(image_path)[1])\n",
    "                fake_image_path = os.path.join(abs_images_dir, label, fake_name)\n",
    "\n",
    "                if not os.path.exists(fake_image_path):\n",
    "                    os.symlink(image_path, fake_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "split_mapping = get_split_mapping(SPLITS_DIR, KERAS_TO_CAFFE_SPLITS.keys(), \n",
    "                                  STREAM_IDS)\n",
    "\n",
    "FAKE_DIR = os.path.join(PROJECT_DIR,'datasets', 'fake_dir')\n",
    "\n",
    "shutil.rmtree(FAKE_DIR)\n",
    "create_fake_directory(FAKE_DIR, split_mapping, LABELS, process_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class threadsafe_iter(object):\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return next(self.it)\n",
    "\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relationToDomainLabel(rel_label):\n",
    "    rel_label = int(rel_label)\n",
    "    \n",
    "    if rel_label in range(0, 4):\n",
    "        return 0\n",
    "    elif rel_label in range(4, 7):\n",
    "        return 1\n",
    "    elif rel_label in range(7, 8):\n",
    "        return 2\n",
    "    elif rel_label in range(8, 12):\n",
    "        return 3\n",
    "    elif rel_label in range(12, 16):\n",
    "        return 4\n",
    "    \n",
    "    raise LookupError('Label out of range: {}. Valid range: [0,16).'.format(rel_label))\n",
    "\n",
    "relationToDomainLabelVec = np.vectorize(relationToDomainLabel)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "IMAGE_SHAPE = (256, 256, 3)\n",
    "#INPUT_SHAPE = (224, 224, 3)\n",
    "INPUT_SHAPE = (227, 227, 3)\n",
    "\n",
    "SHARED_SEED = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def crop_transformation(preprocessing_function, center_crop_size):\n",
    "    def center_crop(x):\n",
    "        centerw, centerh = x.shape[0]//2, x.shape[1]//2\n",
    "        halfw, halfh = center_crop_size[0]//2, center_crop_size[1]//2\n",
    "        new_x = x[centerw-halfw:centerw+halfw,centerh-halfh:centerh+halfh, :]        \n",
    "        return preprocessing_function(new_x)\n",
    "    \n",
    "    return center_crop\n",
    "\n",
    "@threadsafe_generator\n",
    "def multiple_stream_generator(generators, input_names): \n",
    "    assert len(generators) == len(input_names)\n",
    "    \n",
    "    while True:\n",
    "        data_batch = [next(gen) for gen in generators]\n",
    "        # multiple inputs\n",
    "        X = {s_id : data_batch[idx][0] for idx, s_id in enumerate(input_names)}\n",
    "        # just one output (all outputs are the same)\n",
    "        y_rel = data_batch[0][1]\n",
    "        # y_dom = to_categorical(relationToDomainLabelVec(np.argmax(y_rel, axis=1)), DOMAIN_CLASSES)       \n",
    "        y = { \n",
    "           #  'output_domain' : y_dom\n",
    "           # , 'output_relation' : y_rel\n",
    "            'output_domain' : data_batch[1][1]\n",
    "            }\n",
    "        \n",
    "        yield X, y\n",
    "        \n",
    "def create_dataset_generators(directory, classes, batch_size, seed=0, \n",
    "                              input_name_pattern='input_s{}',\n",
    "                              preprocessing_function=None):\n",
    "    generators = {}\n",
    "    input_names = [input_name_pattern.format(s_id)  for s_id in STREAM_IDS]\n",
    "    \n",
    "    for split in ['train', 'test', 'val']:\n",
    "        flow_gens = []\n",
    "\n",
    "        for s_id in STREAM_IDS:\n",
    "            if split == 'train':\n",
    "                datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                             width_shift_range=0.2,\n",
    "                                             height_shift_range=0.2,\n",
    "                                             rotation_range=30,\n",
    "                                             zoom_range=0.2,\n",
    "                                             horizontal_flip=True,\n",
    "                                             preprocessing_function=preprocessing_function)\n",
    "            else:\n",
    "                datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                             preprocessing_function=preprocessing_function)\n",
    "\n",
    "            target_size=(INPUT_SHAPE[0], INPUT_SHAPE[1])\n",
    "            images_dir = os.path.join(directory, split, s_id)\n",
    "            flow_gen = datagen.flow_from_directory(\n",
    "                                images_dir,\n",
    "                                target_size=target_size,\n",
    "                                batch_size=batch_size,\n",
    "                                classes=classes,\n",
    "                                seed=seed,\n",
    "                                follow_links=True)\n",
    "        \n",
    "            flow_gens.append(flow_gen)\n",
    "        \n",
    "        generators[split] = multiple_stream_generator(flow_gens, input_names)\n",
    "\n",
    "    return generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13729 images belonging to 5 classes.\n",
      "Found 13729 images belonging to 5 classes.\n",
      "Found 5106 images belonging to 5 classes.\n",
      "Found 5106 images belonging to 5 classes.\n",
      "Found 709 images belonging to 5 classes.\n",
      "Found 709 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import mobilenet\n",
    "from keras.applications import imagenet_utils\n",
    "\n",
    "generators = create_dataset_generators(FAKE_DIR, LABELS, BATCH_SIZE, SHARED_SEED, \n",
    "                                       preprocessing_function=imagenet_utils.preprocess_input)\n",
    "#                                       preprocessing_function=mobilenet.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(generators['val'])[1]['output_relation'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN, N_TEST, N_VAL = 13729, 5106, 709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import mobilenet\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Reshape, Dropout, Conv2D, Activation\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from keras_squeezenet import squeezenet\n",
    "\n",
    "def create_model(stream_ids, classes, dropout=1e-3):\n",
    "\n",
    "    # create the base pre-trained models\n",
    "    arch = 'SqueezeNet'\n",
    "    if arch == 'MobileNet':\n",
    "        Net = mobilenet.MobileNet\n",
    "    else:\n",
    "        Net = squeezenet.SqueezeNet\n",
    "    \n",
    "    streams = {s_id : Net(weights='imagenet', \n",
    "                          include_top=False, \n",
    "                          pooling = 'avg',\n",
    "#                          alpha=0.75,\n",
    "                          input_shape=INPUT_SHAPE)\n",
    "               for s_id in stream_ids}\n",
    "\n",
    "    # fuse streams\n",
    "    x = keras.layers.concatenate([stream.output for stream in streams.values()])\n",
    "    \n",
    "    # add top\n",
    "    x = Reshape((1,1,-1), name='reshape_concat')(x)\n",
    "    x_dropout = Dropout(dropout, name='dropout_concat')(x)\n",
    "    \n",
    "    outputs = []\n",
    "    for data_type, n_classes in [\n",
    "                                  ('domain', DOMAIN_CLASSES)\n",
    "                                # , ('relation', RELATION_CLASSES)\n",
    "                                ]:\n",
    "        x = Conv2D(n_classes, (1, 1), padding='same', \n",
    "                   name='conv_preds_{}'.format(data_type))(x_dropout)\n",
    "        \n",
    "        x = Activation('softmax', name='act_softmax_{}'.format(data_type))(x)\n",
    "        \n",
    "        prediction = Reshape((n_classes,), \n",
    "                              name='output_{}'.format(data_type))(x)\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    # rename layers to provide unique names\n",
    "    for s_id, stream in streams.items():\n",
    "        stream.layers[0].name = 'input'\n",
    "        for idx, layer in enumerate(stream.layers):\n",
    "            stream.layers[idx].name = layer.name + '_s' + s_id    \n",
    "    \n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=[streams[s_id].input for s_id in stream_ids], outputs=outputs)\n",
    "    \n",
    "    # regularization\n",
    "    min_params_for_l2_reg = 100000000 # 50000\n",
    "    l2_lambda = 0.01    \n",
    "    for layer in model.layers:\n",
    "        if type(layer) == Conv2D and layer.count_params() > min_params_for_l2_reg:\n",
    "            layer.kernel_regularizer = regularizers.l2(l2_lambda)    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuse_model = False\n",
    "train_model = not reuse_model\n",
    "\n",
    "checkpoint_path = os.path.join(BASE_MODELS_DIR, '{}_models'.format(ARCH), \n",
    "                               'weights.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "if reuse_model:\n",
    "    last_epoch, val_loss = 10, 2.04\n",
    "    model_file = checkpoint_path.format(epoch=last_epoch, val_loss=val_loss)\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        model = load_model(model_file, custom_objects={\n",
    "                           'relu6': mobilenet.relu6,\n",
    "                           'DepthwiseConv2D': mobilenet.DepthwiseConv2D})\n",
    "    else:\n",
    "        create_model = True\n",
    "\n",
    "if train_model:\n",
    "    model = create_model(STREAM_IDS, N_CLASSES, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/src/keras/models.py:252: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model.save(checkpoint_path.format(epoch=0, val_loss=0.0))\n",
    "checkpoint_path = os.path.join(BASE_MODELS_DIR, '{}_models'.format(ARCH), \n",
    "                               'weights.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "\n",
    "model = keras.models.load_model(checkpoint_path.format(epoch=0, val_loss=0.0), \n",
    "                                custom_objects={\n",
    "                           'relu6': mobilenet.relu6,\n",
    "                           'DepthwiseConv2D': mobilenet.DepthwiseConv2D})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_s2\n",
      "1 input_s1\n",
      "2 conv1_s2\n",
      "3 conv1_s1\n",
      "4 relu_conv1_s2\n",
      "5 relu_conv1_s1\n",
      "6 pool1_s2\n",
      "7 pool1_s1\n",
      "8 fire2/squeeze1x1_s2\n",
      "9 fire2/squeeze1x1_s1\n",
      "10 fire2/relu_squeeze1x1_s2\n",
      "11 fire2/relu_squeeze1x1_s1\n",
      "12 fire2/expand1x1_s2\n",
      "13 fire2/expand3x3_s2\n",
      "14 fire2/expand1x1_s1\n",
      "15 fire2/expand3x3_s1\n",
      "16 fire2/relu_expand1x1_s2\n",
      "17 fire2/relu_expand3x3_s2\n",
      "18 fire2/relu_expand1x1_s1\n",
      "19 fire2/relu_expand3x3_s1\n",
      "20 fire2/concat_s2\n",
      "21 fire2/concat_s1\n",
      "22 fire3/squeeze1x1_s2\n",
      "23 fire3/squeeze1x1_s1\n",
      "24 fire3/relu_squeeze1x1_s2\n",
      "25 fire3/relu_squeeze1x1_s1\n",
      "26 fire3/expand1x1_s2\n",
      "27 fire3/expand3x3_s2\n",
      "28 fire3/expand1x1_s1\n",
      "29 fire3/expand3x3_s1\n",
      "30 fire3/relu_expand1x1_s2\n",
      "31 fire3/relu_expand3x3_s2\n",
      "32 fire3/relu_expand1x1_s1\n",
      "33 fire3/relu_expand3x3_s1\n",
      "34 fire3/concat_s2\n",
      "35 fire3/concat_s1\n",
      "36 pool3_s2\n",
      "37 pool3_s1\n",
      "38 fire4/squeeze1x1_s2\n",
      "39 fire4/squeeze1x1_s1\n",
      "40 fire4/relu_squeeze1x1_s2\n",
      "41 fire4/relu_squeeze1x1_s1\n",
      "42 fire4/expand1x1_s2\n",
      "43 fire4/expand3x3_s2\n",
      "44 fire4/expand1x1_s1\n",
      "45 fire4/expand3x3_s1\n",
      "46 fire4/relu_expand1x1_s2\n",
      "47 fire4/relu_expand3x3_s2\n",
      "48 fire4/relu_expand1x1_s1\n",
      "49 fire4/relu_expand3x3_s1\n",
      "50 fire4/concat_s2\n",
      "51 fire4/concat_s1\n",
      "52 fire5/squeeze1x1_s2\n",
      "53 fire5/squeeze1x1_s1\n",
      "54 fire5/relu_squeeze1x1_s2\n",
      "55 fire5/relu_squeeze1x1_s1\n",
      "56 fire5/expand1x1_s2\n",
      "57 fire5/expand3x3_s2\n",
      "58 fire5/expand1x1_s1\n",
      "59 fire5/expand3x3_s1\n",
      "60 fire5/relu_expand1x1_s2\n",
      "61 fire5/relu_expand3x3_s2\n",
      "62 fire5/relu_expand1x1_s1\n",
      "63 fire5/relu_expand3x3_s1\n",
      "64 fire5/concat_s2\n",
      "65 fire5/concat_s1\n",
      "66 pool5_s2\n",
      "67 pool5_s1\n",
      "68 fire6/squeeze1x1_s2\n",
      "69 fire6/squeeze1x1_s1\n",
      "70 fire6/relu_squeeze1x1_s2\n",
      "71 fire6/relu_squeeze1x1_s1\n",
      "72 fire6/expand1x1_s2\n",
      "73 fire6/expand3x3_s2\n",
      "74 fire6/expand1x1_s1\n",
      "75 fire6/expand3x3_s1\n",
      "76 fire6/relu_expand1x1_s2\n",
      "77 fire6/relu_expand3x3_s2\n",
      "78 fire6/relu_expand1x1_s1\n",
      "79 fire6/relu_expand3x3_s1\n",
      "80 fire6/concat_s2\n",
      "81 fire6/concat_s1\n",
      "82 fire7/squeeze1x1_s2\n",
      "83 fire7/squeeze1x1_s1\n",
      "84 fire7/relu_squeeze1x1_s2\n",
      "85 fire7/relu_squeeze1x1_s1\n",
      "86 fire7/expand1x1_s2\n",
      "87 fire7/expand3x3_s2\n",
      "88 fire7/expand1x1_s1\n",
      "89 fire7/expand3x3_s1\n",
      "90 fire7/relu_expand1x1_s2\n",
      "91 fire7/relu_expand3x3_s2\n",
      "92 fire7/relu_expand1x1_s1\n",
      "93 fire7/relu_expand3x3_s1\n",
      "94 fire7/concat_s2\n",
      "95 fire7/concat_s1\n",
      "96 fire8/squeeze1x1_s2\n",
      "97 fire8/squeeze1x1_s1\n",
      "98 fire8/relu_squeeze1x1_s2\n",
      "99 fire8/relu_squeeze1x1_s1\n",
      "100 fire8/expand1x1_s2\n",
      "101 fire8/expand3x3_s2\n",
      "102 fire8/expand1x1_s1\n",
      "103 fire8/expand3x3_s1\n",
      "104 fire8/relu_expand1x1_s2\n",
      "105 fire8/relu_expand3x3_s2\n",
      "106 fire8/relu_expand1x1_s1\n",
      "107 fire8/relu_expand3x3_s1\n",
      "108 fire8/concat_s2\n",
      "109 fire8/concat_s1\n",
      "110 fire9/squeeze1x1_s2\n",
      "111 fire9/squeeze1x1_s1\n",
      "112 fire9/relu_squeeze1x1_s2\n",
      "113 fire9/relu_squeeze1x1_s1\n",
      "114 fire9/expand1x1_s2\n",
      "115 fire9/expand3x3_s2\n",
      "116 fire9/expand1x1_s1\n",
      "117 fire9/expand3x3_s1\n",
      "118 fire9/relu_expand1x1_s2\n",
      "119 fire9/relu_expand3x3_s2\n",
      "120 fire9/relu_expand1x1_s1\n",
      "121 fire9/relu_expand3x3_s1\n",
      "122 fire9/concat_s2\n",
      "123 fire9/concat_s1\n",
      "124 global_average_pooling2d_4_s2\n",
      "125 global_average_pooling2d_3_s1\n",
      "126 concatenate_2\n",
      "127 reshape_concat\n",
      "128 dropout_concat\n",
      "129 conv_preds_domain\n",
      "130 act_softmax_domain\n",
      "131 output_domain\n"
     ]
    }
   ],
   "source": [
    "for idx, layer in enumerate(model.layers):\n",
    "    layer.trainable = True\n",
    "    print(idx, layer.name)\n",
    "    \n",
    "freeze = True\n",
    "if freeze:\n",
    "    n_blocks = 11 # set from 0 to 13\n",
    "    freeze_idx = 164 - 6 * 2 * n_blocks\n",
    "    \n",
    "    freeze_idx = 126\n",
    "    for layer in model.layers[:freeze_idx]:\n",
    "        layer.trainable = not freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_s2 (InputLayer)           (None, 227, 227, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_s1 (InputLayer)           (None, 227, 227, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_s2 (Conv2D)               (None, 113, 113, 64) 1792        input_s2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_s1 (Conv2D)               (None, 113, 113, 64) 1792        input_s1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1_s2 (Activation)      (None, 113, 113, 64) 0           conv1_s2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1_s1 (Activation)      (None, 113, 113, 64) 0           conv1_s1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_s2 (MaxPooling2D)         (None, 56, 56, 64)   0           relu_conv1_s2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pool1_s1 (MaxPooling2D)         (None, 56, 56, 64)   0           relu_conv1_s1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1_s2 (Conv2D)    (None, 56, 56, 16)   1040        pool1_s2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1_s1 (Conv2D)    (None, 56, 56, 16)   1040        pool1_s1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1_s2 (Activ (None, 56, 56, 16)   0           fire2/squeeze1x1_s2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1_s1 (Activ (None, 56, 56, 16)   0           fire2/squeeze1x1_s1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1_s2 (Conv2D)     (None, 56, 56, 64)   1088        fire2/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3_s2 (Conv2D)     (None, 56, 56, 64)   9280        fire2/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1_s1 (Conv2D)     (None, 56, 56, 64)   1088        fire2/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3_s1 (Conv2D)     (None, 56, 56, 64)   9280        fire2/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1_s2 (Activa (None, 56, 56, 64)   0           fire2/expand1x1_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3_s2 (Activa (None, 56, 56, 64)   0           fire2/expand3x3_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1_s1 (Activa (None, 56, 56, 64)   0           fire2/expand1x1_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3_s1 (Activa (None, 56, 56, 64)   0           fire2/expand3x3_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat_s2 (Concatenate)   (None, 56, 56, 128)  0           fire2/relu_expand1x1_s2[0][0]    \n",
      "                                                                 fire2/relu_expand3x3_s2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat_s1 (Concatenate)   (None, 56, 56, 128)  0           fire2/relu_expand1x1_s1[0][0]    \n",
      "                                                                 fire2/relu_expand3x3_s1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1_s2 (Conv2D)    (None, 56, 56, 16)   2064        fire2/concat_s2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1_s1 (Conv2D)    (None, 56, 56, 16)   2064        fire2/concat_s1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1_s2 (Activ (None, 56, 56, 16)   0           fire3/squeeze1x1_s2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1_s1 (Activ (None, 56, 56, 16)   0           fire3/squeeze1x1_s1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1_s2 (Conv2D)     (None, 56, 56, 64)   1088        fire3/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3_s2 (Conv2D)     (None, 56, 56, 64)   9280        fire3/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1_s1 (Conv2D)     (None, 56, 56, 64)   1088        fire3/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3_s1 (Conv2D)     (None, 56, 56, 64)   9280        fire3/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1_s2 (Activa (None, 56, 56, 64)   0           fire3/expand1x1_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3_s2 (Activa (None, 56, 56, 64)   0           fire3/expand3x3_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1_s1 (Activa (None, 56, 56, 64)   0           fire3/expand1x1_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3_s1 (Activa (None, 56, 56, 64)   0           fire3/expand3x3_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat_s2 (Concatenate)   (None, 56, 56, 128)  0           fire3/relu_expand1x1_s2[0][0]    \n",
      "                                                                 fire3/relu_expand3x3_s2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat_s1 (Concatenate)   (None, 56, 56, 128)  0           fire3/relu_expand1x1_s1[0][0]    \n",
      "                                                                 fire3/relu_expand3x3_s1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "pool3_s2 (MaxPooling2D)         (None, 27, 27, 128)  0           fire3/concat_s2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "pool3_s1 (MaxPooling2D)         (None, 27, 27, 128)  0           fire3/concat_s1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1_s2 (Conv2D)    (None, 27, 27, 32)   4128        pool3_s2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1_s1 (Conv2D)    (None, 27, 27, 32)   4128        pool3_s1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1_s2 (Activ (None, 27, 27, 32)   0           fire4/squeeze1x1_s2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1_s1 (Activ (None, 27, 27, 32)   0           fire4/squeeze1x1_s1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1_s2 (Conv2D)     (None, 27, 27, 128)  4224        fire4/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3_s2 (Conv2D)     (None, 27, 27, 128)  36992       fire4/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1_s1 (Conv2D)     (None, 27, 27, 128)  4224        fire4/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3_s1 (Conv2D)     (None, 27, 27, 128)  36992       fire4/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1_s2 (Activa (None, 27, 27, 128)  0           fire4/expand1x1_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3_s2 (Activa (None, 27, 27, 128)  0           fire4/expand3x3_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1_s1 (Activa (None, 27, 27, 128)  0           fire4/expand1x1_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3_s1 (Activa (None, 27, 27, 128)  0           fire4/expand3x3_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat_s2 (Concatenate)   (None, 27, 27, 256)  0           fire4/relu_expand1x1_s2[0][0]    \n",
      "                                                                 fire4/relu_expand3x3_s2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat_s1 (Concatenate)   (None, 27, 27, 256)  0           fire4/relu_expand1x1_s1[0][0]    \n",
      "                                                                 fire4/relu_expand3x3_s1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1_s2 (Conv2D)    (None, 27, 27, 32)   8224        fire4/concat_s2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1_s1 (Conv2D)    (None, 27, 27, 32)   8224        fire4/concat_s1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1_s2 (Activ (None, 27, 27, 32)   0           fire5/squeeze1x1_s2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1_s1 (Activ (None, 27, 27, 32)   0           fire5/squeeze1x1_s1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1_s2 (Conv2D)     (None, 27, 27, 128)  4224        fire5/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3_s2 (Conv2D)     (None, 27, 27, 128)  36992       fire5/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1_s1 (Conv2D)     (None, 27, 27, 128)  4224        fire5/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3_s1 (Conv2D)     (None, 27, 27, 128)  36992       fire5/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1_s2 (Activa (None, 27, 27, 128)  0           fire5/expand1x1_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3_s2 (Activa (None, 27, 27, 128)  0           fire5/expand3x3_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1_s1 (Activa (None, 27, 27, 128)  0           fire5/expand1x1_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3_s1 (Activa (None, 27, 27, 128)  0           fire5/expand3x3_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat_s2 (Concatenate)   (None, 27, 27, 256)  0           fire5/relu_expand1x1_s2[0][0]    \n",
      "                                                                 fire5/relu_expand3x3_s2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat_s1 (Concatenate)   (None, 27, 27, 256)  0           fire5/relu_expand1x1_s1[0][0]    \n",
      "                                                                 fire5/relu_expand3x3_s1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "pool5_s2 (MaxPooling2D)         (None, 13, 13, 256)  0           fire5/concat_s2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "pool5_s1 (MaxPooling2D)         (None, 13, 13, 256)  0           fire5/concat_s1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1_s2 (Conv2D)    (None, 13, 13, 48)   12336       pool5_s2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1_s1 (Conv2D)    (None, 13, 13, 48)   12336       pool5_s1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1_s2 (Activ (None, 13, 13, 48)   0           fire6/squeeze1x1_s2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1_s1 (Activ (None, 13, 13, 48)   0           fire6/squeeze1x1_s1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1_s2 (Conv2D)     (None, 13, 13, 192)  9408        fire6/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3_s2 (Conv2D)     (None, 13, 13, 192)  83136       fire6/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1_s1 (Conv2D)     (None, 13, 13, 192)  9408        fire6/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3_s1 (Conv2D)     (None, 13, 13, 192)  83136       fire6/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1_s2 (Activa (None, 13, 13, 192)  0           fire6/expand1x1_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3_s2 (Activa (None, 13, 13, 192)  0           fire6/expand3x3_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1_s1 (Activa (None, 13, 13, 192)  0           fire6/expand1x1_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3_s1 (Activa (None, 13, 13, 192)  0           fire6/expand3x3_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat_s2 (Concatenate)   (None, 13, 13, 384)  0           fire6/relu_expand1x1_s2[0][0]    \n",
      "                                                                 fire6/relu_expand3x3_s2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat_s1 (Concatenate)   (None, 13, 13, 384)  0           fire6/relu_expand1x1_s1[0][0]    \n",
      "                                                                 fire6/relu_expand3x3_s1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1_s2 (Conv2D)    (None, 13, 13, 48)   18480       fire6/concat_s2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1_s1 (Conv2D)    (None, 13, 13, 48)   18480       fire6/concat_s1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1_s2 (Activ (None, 13, 13, 48)   0           fire7/squeeze1x1_s2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1_s1 (Activ (None, 13, 13, 48)   0           fire7/squeeze1x1_s1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1_s2 (Conv2D)     (None, 13, 13, 192)  9408        fire7/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3_s2 (Conv2D)     (None, 13, 13, 192)  83136       fire7/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1_s1 (Conv2D)     (None, 13, 13, 192)  9408        fire7/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3_s1 (Conv2D)     (None, 13, 13, 192)  83136       fire7/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1_s2 (Activa (None, 13, 13, 192)  0           fire7/expand1x1_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3_s2 (Activa (None, 13, 13, 192)  0           fire7/expand3x3_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1_s1 (Activa (None, 13, 13, 192)  0           fire7/expand1x1_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3_s1 (Activa (None, 13, 13, 192)  0           fire7/expand3x3_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat_s2 (Concatenate)   (None, 13, 13, 384)  0           fire7/relu_expand1x1_s2[0][0]    \n",
      "                                                                 fire7/relu_expand3x3_s2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat_s1 (Concatenate)   (None, 13, 13, 384)  0           fire7/relu_expand1x1_s1[0][0]    \n",
      "                                                                 fire7/relu_expand3x3_s1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1_s2 (Conv2D)    (None, 13, 13, 64)   24640       fire7/concat_s2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1_s1 (Conv2D)    (None, 13, 13, 64)   24640       fire7/concat_s1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1_s2 (Activ (None, 13, 13, 64)   0           fire8/squeeze1x1_s2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1_s1 (Activ (None, 13, 13, 64)   0           fire8/squeeze1x1_s1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1_s2 (Conv2D)     (None, 13, 13, 256)  16640       fire8/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3_s2 (Conv2D)     (None, 13, 13, 256)  147712      fire8/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1_s1 (Conv2D)     (None, 13, 13, 256)  16640       fire8/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3_s1 (Conv2D)     (None, 13, 13, 256)  147712      fire8/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1_s2 (Activa (None, 13, 13, 256)  0           fire8/expand1x1_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3_s2 (Activa (None, 13, 13, 256)  0           fire8/expand3x3_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1_s1 (Activa (None, 13, 13, 256)  0           fire8/expand1x1_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3_s1 (Activa (None, 13, 13, 256)  0           fire8/expand3x3_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat_s2 (Concatenate)   (None, 13, 13, 512)  0           fire8/relu_expand1x1_s2[0][0]    \n",
      "                                                                 fire8/relu_expand3x3_s2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat_s1 (Concatenate)   (None, 13, 13, 512)  0           fire8/relu_expand1x1_s1[0][0]    \n",
      "                                                                 fire8/relu_expand3x3_s1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1_s2 (Conv2D)    (None, 13, 13, 64)   32832       fire8/concat_s2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1_s1 (Conv2D)    (None, 13, 13, 64)   32832       fire8/concat_s1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1_s2 (Activ (None, 13, 13, 64)   0           fire9/squeeze1x1_s2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1_s1 (Activ (None, 13, 13, 64)   0           fire9/squeeze1x1_s1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1_s2 (Conv2D)     (None, 13, 13, 256)  16640       fire9/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3_s2 (Conv2D)     (None, 13, 13, 256)  147712      fire9/relu_squeeze1x1_s2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1_s1 (Conv2D)     (None, 13, 13, 256)  16640       fire9/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3_s1 (Conv2D)     (None, 13, 13, 256)  147712      fire9/relu_squeeze1x1_s1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1_s2 (Activa (None, 13, 13, 256)  0           fire9/expand1x1_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3_s2 (Activa (None, 13, 13, 256)  0           fire9/expand3x3_s2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1_s1 (Activa (None, 13, 13, 256)  0           fire9/expand1x1_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3_s1 (Activa (None, 13, 13, 256)  0           fire9/expand3x3_s1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat_s2 (Concatenate)   (None, 13, 13, 512)  0           fire9/relu_expand1x1_s2[0][0]    \n",
      "                                                                 fire9/relu_expand3x3_s2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat_s1 (Concatenate)   (None, 13, 13, 512)  0           fire9/relu_expand1x1_s1[0][0]    \n",
      "                                                                 fire9/relu_expand3x3_s1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4_s2 ( (None, 512)          0           fire9/concat_s2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3_s1 ( (None, 512)          0           fire9/concat_s1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1024)         0           global_average_pooling2d_4_s2[0][\n",
      "                                                                 global_average_pooling2d_3_s1[0][\n",
      "__________________________________________________________________________________________________\n",
      "reshape_concat (Reshape)        (None, 1, 1, 1024)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_concat (Dropout)        (None, 1, 1, 1024)   0           reshape_concat[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_preds_domain (Conv2D)      (None, 1, 1, 5)      5125        dropout_concat[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "act_softmax_domain (Activation) (None, 1, 1, 5)      0           conv_preds_domain[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "output_domain (Reshape)         (None, 5)            0           act_softmax_domain[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 1,450,117\n",
      "Trainable params: 5,125\n",
      "Non-trainable params: 1,444,992\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "430/430 [==============================] - 254s 591ms/step - loss: 1.2309 - acc: 0.5748 - val_loss: 1.5724 - val_acc: 0.4598\n",
      "Epoch 2/10\n",
      "430/430 [==============================] - 227s 529ms/step - loss: 1.0096 - acc: 0.6389 - val_loss: 1.6461 - val_acc: 0.4429\n",
      "Epoch 3/10\n",
      "430/430 [==============================] - 233s 541ms/step - loss: 0.9473 - acc: 0.6643 - val_loss: 1.5981 - val_acc: 0.4104\n",
      "Epoch 4/10\n",
      "430/430 [==============================] - 221s 515ms/step - loss: 0.9208 - acc: 0.6771 - val_loss: 1.5599 - val_acc: 0.4133\n",
      "Epoch 5/10\n",
      "430/430 [==============================] - 232s 540ms/step - loss: 0.9101 - acc: 0.6767 - val_loss: 1.6857 - val_acc: 0.4260\n",
      "Epoch 6/10\n",
      "430/430 [==============================] - 224s 522ms/step - loss: 0.9046 - acc: 0.6746 - val_loss: 1.5558 - val_acc: 0.4245\n",
      "Epoch 7/10\n",
      "430/430 [==============================] - 234s 543ms/step - loss: 0.8875 - acc: 0.6872 - val_loss: 1.3776 - val_acc: 0.4217\n",
      "Epoch 8/10\n",
      "430/430 [==============================] - 211s 491ms/step - loss: 0.8989 - acc: 0.6778 - val_loss: 1.4117 - val_acc: 0.4330\n",
      "Epoch 9/10\n",
      "430/430 [==============================] - 223s 518ms/step - loss: 0.8817 - acc: 0.6828 - val_loss: 1.6984 - val_acc: 0.4189\n",
      "Epoch 10/10\n",
      "430/430 [==============================] - 208s 484ms/step - loss: 0.8873 - acc: 0.6883 - val_loss: 1.3835 - val_acc: 0.4118\n",
      "[1.1720428524697195, 0.54328241288265056]\n",
      "Epoch 11/30\n",
      "430/430 [==============================] - 220s 511ms/step - loss: 0.8516 - acc: 0.6920 - val_loss: 1.5708 - val_acc: 0.4175\n",
      "Epoch 12/30\n",
      "430/430 [==============================] - 221s 513ms/step - loss: 0.8622 - acc: 0.6847 - val_loss: 1.5221 - val_acc: 0.4288\n",
      "Epoch 13/30\n",
      "430/430 [==============================] - 219s 509ms/step - loss: 0.8615 - acc: 0.6879 - val_loss: 1.4880 - val_acc: 0.4161\n",
      "Epoch 14/30\n",
      "430/430 [==============================] - 241s 561ms/step - loss: 0.8702 - acc: 0.6805 - val_loss: 1.4647 - val_acc: 0.4415\n",
      "Epoch 15/30\n",
      "430/430 [==============================] - 224s 520ms/step - loss: 0.8545 - acc: 0.6916 - val_loss: 1.4496 - val_acc: 0.4274\n",
      "Epoch 16/30\n",
      "430/430 [==============================] - 225s 523ms/step - loss: 0.8559 - acc: 0.6919 - val_loss: 1.7417 - val_acc: 0.4429\n",
      "Epoch 17/30\n",
      "430/430 [==============================] - 222s 515ms/step - loss: 0.8562 - acc: 0.6903 - val_loss: 1.4242 - val_acc: 0.4104\n",
      "Epoch 18/30\n",
      "430/430 [==============================] - 222s 516ms/step - loss: 0.8496 - acc: 0.6922 - val_loss: 1.4707 - val_acc: 0.4358\n",
      "Epoch 19/30\n",
      "430/430 [==============================] - 225s 524ms/step - loss: 0.8497 - acc: 0.6953 - val_loss: 1.5796 - val_acc: 0.4358\n",
      "Epoch 20/30\n",
      " 84/430 [====>.........................] - ETA: 2:38 - loss: 0.8665 - acc: 0.6823"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-fc6472fb2b7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_VAL\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             workers=4, max_queue_size=5)\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     metrics = model.evaluate_generator(generators['test'], \n",
      "\u001b[0;32m/src/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/src/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    713\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "callbacks = [ \n",
    "              ModelCheckpoint(checkpoint_path, monitor='val_loss', period=1)\n",
    "            , TensorBoard(log_dir=LOGS_DIR, write_images=True, write_graph=True)\n",
    "            ]\n",
    "\n",
    "pretraining = True\n",
    "pretraining_epochs = 10\n",
    "if pretraining:\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional Mobilenet layers\n",
    "    # freeze(model, n_blocks='all')\n",
    "\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    optimizer = 'adam' # 'rmsprop'\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # train the model on the new data for a few epochs\n",
    "    model.fit_generator(\n",
    "            generators['train'],\n",
    "            steps_per_epoch=np.ceil(N_TRAIN / BATCH_SIZE),\n",
    "            epochs=pretraining_epochs,\n",
    "            validation_data=generators['val'],\n",
    "            validation_steps=np.ceil(N_VAL / BATCH_SIZE),\n",
    "            callbacks=callbacks,\n",
    "            workers=4,\n",
    "            max_queue_size=5)\n",
    "\n",
    "    metrics = model.evaluate_generator(generators['test'], \n",
    "                                       steps=np.ceil(N_TEST / BATCH_SIZE),\n",
    "                                       max_queue_size=5, workers=4)    \n",
    "    print(metrics)\n",
    "    \n",
    "    last_epoch = pretraining_epochs\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "post_training = True\n",
    "post_training_epochs = 20\n",
    "if post_training:\n",
    "    # unfreeze the model\n",
    "    # unfreeze(model, n_blocks='all')\n",
    "    # freeze 3 blocks\n",
    "    # freeze(model, n_blocks=3)\n",
    "\n",
    "    # we need to recompile the model for these modifications to take effect\n",
    "    # we use SGD with a low learning rate\n",
    "    from keras.optimizers import SGD\n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "    # alongside the top Dense layers\n",
    "    model.fit_generator(\n",
    "            generators['train'],\n",
    "            steps_per_epoch=np.ceil(N_TRAIN / BATCH_SIZE),\n",
    "            epochs=last_epoch + post_training_epochs,\n",
    "            validation_data=generators['val'],\n",
    "            validation_steps=np.ceil(N_VAL / BATCH_SIZE),\n",
    "            callbacks=callbacks, initial_epoch=last_epoch,\n",
    "            workers=4, max_queue_size=5)\n",
    "\n",
    "    metrics = model.evaluate_generator(generators['test'], \n",
    "                                       steps=np.ceil(N_TEST / BATCH_SIZE), \n",
    "                                       workers=4, max_queue_size=5)\n",
    "\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1586970219040589, 0.5595377986682335]\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate_generator(generators['test'], \n",
    "                                   steps=np.ceil(N_TEST / BATCH_SIZE), \n",
    "                                   max_queue_size=5, workers=4)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tensorflow_gpu():\n",
    "    import tensorflow as tf\n",
    "    with tf.device('/gpu:0'):\n",
    "        a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "        b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "        c = tf.matmul(a, b)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print (sess.run(c))\n",
    "\n",
    "check_tensorflow_gpu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
