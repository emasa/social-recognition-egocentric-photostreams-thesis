{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from __future__ import print_function\n",
    "\n",
    "DEPRECATED_HOME = '/root'\n",
    "\n",
    "PROJECT_DIR = '~/shared/Documents/final_proj'\n",
    "PROJECT_DIR = os.path.expanduser(PROJECT_DIR)\n",
    "\n",
    "BASE_MODELS_DIR = os.path.join(PROJECT_DIR, 'models/trained_models')\n",
    "ATTR_MODELS_DIR = os.path.join(BASE_MODELS_DIR, 'attribute_models')\n",
    "BASE_FEATURES_DIR = os.path.join(PROJECT_DIR, 'extracted_features')\n",
    "SVM_MODELS_DIR = os.path.join(PROJECT_DIR, 'models/svm_models')\n",
    "SPLITS_DIR = os.path.join(PROJECT_DIR,'datasets/splits/annotator_consistency3')\n",
    "STATS_MODELS_DIR = os.path.join(SVM_MODELS_DIR, 'stats')\n",
    "LOGS_DIR = os.path.join(PROJECT_DIR, 'logs')\n",
    "\n",
    "ARCH = 'mobileNet'\n",
    "LAYER = 'fc7'\n",
    "\n",
    "DOMAIN='domain'\n",
    "RELATION='relation'\n",
    "DATA_TYPE=DOMAIN\n",
    "\n",
    "CONFIG = LAYER + '_' + DATA_TYPE + '_' + ARCH\n",
    "\n",
    "DOMAIN_CLASSES, RELATION_CLASSES = 5, 16\n",
    "\n",
    "if DATA_TYPE == DOMAIN:\n",
    "    N_CLASSES = DOMAIN_CLASSES\n",
    "    labels_path = os.path.join(SPLITS_DIR,'domain_single_body1_{}_5.txt')\n",
    "else:\n",
    "    N_CLASSES = RELATION_CLASSES\n",
    "    labels_path = os.path.join(SPLITS_DIR,'single_body1_{}_16.txt')    \n",
    "\n",
    "LABELS = [str(label) for label in range(N_CLASSES)]  \n",
    "\n",
    "end2end_model = True\n",
    "\n",
    "if end2end_model:\n",
    "    FEATURES_DIR = os.path.join(BASE_FEATURES_DIR, 'end_to_end_features', CONFIG)    \n",
    "else:    \n",
    "    FEATURES_DIR = os.path.join(BASE_FEATURES_DIR, 'attribute_features', CONFIG)\n",
    "\n",
    "stored_features_dir = os.path.join(FEATURES_DIR, 'all_splits_numpy_format')\n",
    "\n",
    "N_STREAMS = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "KERAS_TO_CAFFE_SPLITS = {'train': 'train', 'test': 'eval', 'val': 'test'}\n",
    "FILE_FORMAT = '{}single_body'.format('domain_' if DATA_TYPE == DOMAIN else \"\") \\\n",
    "            + '{input_idx}_{split}_' + str(N_CLASSES) + '.txt'\n",
    "\n",
    "STREAM_IDS = [str(idx) for idx in [1, 2]]\n",
    "\n",
    "def process_line(line):\n",
    "    image_path, label = line.strip().split(' ')\n",
    "    image_path = image_path.replace(DEPRECATED_HOME, '~')\n",
    "\n",
    "    if '~' in image_path:\n",
    "        image_path = os.path.expanduser(image_path)\n",
    "\n",
    "    return image_path, label\n",
    "\n",
    "def get_file_name(split, input_idx, f_pattern=FILE_FORMAT):\n",
    "    return f_pattern.format(split=KERAS_TO_CAFFE_SPLITS[split],\n",
    "                            input_idx=input_idx)\n",
    "\n",
    "def get_split_mapping(files_dir, splits, input_indices, f_pattern=FILE_FORMAT):\n",
    "    mapping = {}\n",
    "    for split in splits:\n",
    "        for input_idx in input_indices:\n",
    "            key = os.path.join(split, input_idx)\n",
    "            value =  os.path.join(files_dir, get_file_name(split, input_idx, f_pattern))\n",
    "            mapping[key] = value\n",
    "    \n",
    "    return mapping\n",
    "\n",
    "def create_fake_directory(root_dir, split_mapping, labels, process_line_cb):\n",
    "    if not os.path.exists(root_dir):\n",
    "        os.mkdir(root_dir)\n",
    "    \n",
    "    for images_dir, images_file in split_mapping.items():\n",
    "        abs_images_dir = os.path.join(root_dir, images_dir)\n",
    "        \n",
    "        for label in labels:\n",
    "            label_dir = os.path.join(abs_images_dir, label)\n",
    "            if not os.path.exists(label_dir):\n",
    "                os.makedirs(label_dir)\n",
    "\n",
    "        abs_images_file = os.path.join(abs_images_dir, images_file)\n",
    "        with open(abs_images_file) as f:\n",
    "            for fake_id, line in enumerate(f):\n",
    "                image_path, label = process_line_cb(line)\n",
    "                fake_name = '{}{}'.format(fake_id, os.path.splitext(image_path)[1])\n",
    "                fake_image_path = os.path.join(abs_images_dir, label, fake_name)\n",
    "\n",
    "                if not os.path.exists(fake_image_path):\n",
    "                    os.symlink(image_path, fake_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "split_mapping = get_split_mapping(SPLITS_DIR, KERAS_TO_CAFFE_SPLITS.keys(), \n",
    "                                  STREAM_IDS)\n",
    "\n",
    "FAKE_DIR = os.path.join(PROJECT_DIR,'datasets', 'fake_dir')\n",
    "\n",
    "shutil.rmtree(FAKE_DIR)\n",
    "create_fake_directory(FAKE_DIR, split_mapping, LABELS, process_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class threadsafe_iter(object):\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return next(self.it)\n",
    "\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relationToDomainLabel(rel_label):\n",
    "    rel_label = int(rel_label)\n",
    "    \n",
    "    if rel_label in range(0, 4):\n",
    "        return 0\n",
    "    elif rel_label in range(4, 7):\n",
    "        return 1\n",
    "    elif rel_label in range(7, 8):\n",
    "        return 2\n",
    "    elif rel_label in range(8, 12):\n",
    "        return 3\n",
    "    elif rel_label in range(12, 16):\n",
    "        return 4\n",
    "    \n",
    "    raise LookupError('Label out of range: {}. Valid range: [0,16).'.format(rel_label))\n",
    "\n",
    "relationToDomainLabelVec = np.vectorize(relationToDomainLabel)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "IMAGE_SHAPE = (256, 256, 3)\n",
    "#INPUT_SHAPE = (224, 224, 3)\n",
    "INPUT_SHAPE = (227, 227, 3)\n",
    "\n",
    "SHARED_SEED = 1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def crop_transformation(preprocessing_function, center_crop_size):\n",
    "    def center_crop(x):\n",
    "        centerw, centerh = x.shape[0]//2, x.shape[1]//2\n",
    "        halfw, halfh = center_crop_size[0]//2, center_crop_size[1]//2\n",
    "        new_x = x[centerw-halfw:centerw+halfw,centerh-halfh:centerh+halfh, :]        \n",
    "        return preprocessing_function(new_x)\n",
    "    \n",
    "    return center_crop\n",
    "\n",
    "@threadsafe_generator\n",
    "def multiple_stream_generator(generators, input_names): \n",
    "    assert len(generators) == len(input_names)\n",
    "    \n",
    "    while True:\n",
    "        data_batch = [next(gen) for gen in generators]\n",
    "        # multiple inputs\n",
    "        X = {s_id : data_batch[idx][0] for idx, s_id in enumerate(input_names)}\n",
    "        # just one output (all outputs are the same)\n",
    "        y_rel = data_batch[0][1]\n",
    "        # y_dom = to_categorical(relationToDomainLabelVec(np.argmax(y_rel, axis=1)), DOMAIN_CLASSES)       \n",
    "        y = { \n",
    "           #  'output_domain' : y_dom\n",
    "           # , 'output_relation' : y_rel\n",
    "            'output_domain' : data_batch[1][1]\n",
    "            }\n",
    "        \n",
    "        yield X, y\n",
    "        \n",
    "def create_dataset_generators(directory, classes, batch_size, seed=0, \n",
    "                              input_name_pattern='input_s{}',\n",
    "                              preprocessing_function=None):\n",
    "    generators = {}\n",
    "    input_names = [input_name_pattern.format(s_id)  for s_id in STREAM_IDS]\n",
    "    \n",
    "    for split in ['train', 'test', 'val']:\n",
    "        flow_gens = []\n",
    "\n",
    "        for s_id in STREAM_IDS:\n",
    "            if split == 'train':\n",
    "                datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                             width_shift_range=0.2,\n",
    "                                             height_shift_range=0.2,\n",
    "                                             rotation_range=30,\n",
    "                                             zoom_range=0.2,\n",
    "                                             horizontal_flip=True,\n",
    "                                             preprocessing_function=preprocessing_function)\n",
    "            else:\n",
    "                datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                             preprocessing_function=preprocessing_function)\n",
    "\n",
    "            target_size=(INPUT_SHAPE[0], INPUT_SHAPE[1])\n",
    "            images_dir = os.path.join(directory, split, s_id)\n",
    "            flow_gen = datagen.flow_from_directory(\n",
    "                                images_dir,\n",
    "                                target_size=target_size,\n",
    "                                batch_size=batch_size,\n",
    "                                classes=classes,\n",
    "                                seed=seed,\n",
    "                                follow_links=True)\n",
    "        \n",
    "            flow_gens.append(flow_gen)\n",
    "        \n",
    "        generators[split] = multiple_stream_generator(flow_gens, input_names)\n",
    "\n",
    "    return generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import mobilenet\n",
    "from keras.applications import imagenet_utils\n",
    "\n",
    "generators = create_dataset_generators(FAKE_DIR, LABELS, BATCH_SIZE, SHARED_SEED, \n",
    "                                       preprocessing_function=imagenet_utils.preprocess_input)\n",
    "#                                       preprocessing_function=mobilenet.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(generators['val'])[1]['output_relation'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN, N_TEST, N_VAL = 13729, 5106, 709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import mobilenet\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Reshape, Dropout, Conv2D, Activation\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from keras_squeezenet import squeezenet\n",
    "\n",
    "def create_model(stream_ids, classes, dropout=1e-3):\n",
    "\n",
    "    # create the base pre-trained models\n",
    "    arch = 'SqueezeNet'\n",
    "    if arch == 'MobileNet':\n",
    "        Net = mobilenet.MobileNet\n",
    "    else:\n",
    "        Net = squeezenet.SqueezeNet\n",
    "    \n",
    "    streams = {s_id : Net(weights='imagenet', \n",
    "                          include_top=False, \n",
    "                          pooling = 'avg',\n",
    "#                          alpha=0.75,\n",
    "                          input_shape=INPUT_SHAPE)\n",
    "               for s_id in stream_ids}\n",
    "\n",
    "    # fuse streams\n",
    "    x = keras.layers.concatenate([stream.output for stream in streams.values()])\n",
    "    \n",
    "    # add top\n",
    "    x = Reshape((1,1,-1), name='reshape_concat')(x)\n",
    "    x_dropout = Dropout(dropout, name='dropout_concat')(x)\n",
    "    \n",
    "    outputs = []\n",
    "    for data_type, n_classes in [\n",
    "                                  ('domain', DOMAIN_CLASSES)\n",
    "                                # , ('relation', RELATION_CLASSES)\n",
    "                                ]:\n",
    "        x = Conv2D(n_classes, (1, 1), padding='same', \n",
    "                   name='conv_preds_{}'.format(data_type))(x_dropout)\n",
    "        \n",
    "        x = Activation('softmax', name='act_softmax_{}'.format(data_type))(x)\n",
    "        \n",
    "        prediction = Reshape((n_classes,), \n",
    "                              name='output_{}'.format(data_type))(x)\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    # rename layers to provide unique names\n",
    "    for s_id, stream in streams.items():\n",
    "        stream.layers[0].name = 'input'\n",
    "        for idx, layer in enumerate(stream.layers):\n",
    "            stream.layers[idx].name = layer.name + '_s' + s_id    \n",
    "    \n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=[streams[s_id].input for s_id in stream_ids], outputs=outputs)\n",
    "    \n",
    "    # regularization\n",
    "    min_params_for_l2_reg = 100000000 # 50000\n",
    "    l2_lambda = 0.01    \n",
    "    for layer in model.layers:\n",
    "        if type(layer) == Conv2D and layer.count_params() > min_params_for_l2_reg:\n",
    "            layer.kernel_regularizer = regularizers.l2(l2_lambda)    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuse_model = False\n",
    "train_model = not reuse_model\n",
    "\n",
    "checkpoint_path = os.path.join(BASE_MODELS_DIR, '{}_models'.format(ARCH), \n",
    "                               'weights.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "if reuse_model:\n",
    "    last_epoch, val_loss = 10, 2.04\n",
    "    model_file = checkpoint_path.format(epoch=last_epoch, val_loss=val_loss)\n",
    "\n",
    "    if os.path.exists(model_file):\n",
    "        model = load_model(model_file, custom_objects={\n",
    "                           'relu6': mobilenet.relu6,\n",
    "                           'DepthwiseConv2D': mobilenet.DepthwiseConv2D})\n",
    "    else:\n",
    "        create_model = True\n",
    "\n",
    "if train_model:\n",
    "    model = create_model(STREAM_IDS, N_CLASSES, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(checkpoint_path.format(epoch=0, val_loss=0.0))\n",
    "checkpoint_path = os.path.join(BASE_MODELS_DIR, '{}_models'.format(ARCH), \n",
    "                               'weights.{epoch:02d}-{val_loss:.2f}.hdf5')\n",
    "\n",
    "model = keras.models.load_model(checkpoint_path.format(epoch=0, val_loss=0.0), \n",
    "                                custom_objects={\n",
    "                           'relu6': mobilenet.relu6,\n",
    "                           'DepthwiseConv2D': mobilenet.DepthwiseConv2D})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, layer in enumerate(model.layers):\n",
    "    layer.trainable = True\n",
    "    print(idx, layer.name)\n",
    "    \n",
    "freeze = True\n",
    "if freeze:\n",
    "    n_blocks = 11 # set from 0 to 13\n",
    "    freeze_idx = 164 - 6 * 2 * n_blocks\n",
    "    \n",
    "    freeze_idx = 126\n",
    "    for layer in model.layers[:freeze_idx]:\n",
    "        layer.trainable = not freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ \n",
    "              ModelCheckpoint(checkpoint_path, monitor='val_loss', period=1)\n",
    "            , TensorBoard(log_dir=LOGS_DIR, write_images=True, write_graph=True)\n",
    "            ]\n",
    "\n",
    "pretraining = True\n",
    "pretraining_epochs = 10\n",
    "if pretraining:\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional Mobilenet layers\n",
    "    # freeze(model, n_blocks='all')\n",
    "\n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    optimizer = 'adam' # 'rmsprop'\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # train the model on the new data for a few epochs\n",
    "    model.fit_generator(\n",
    "            generators['train'],\n",
    "            steps_per_epoch=np.ceil(N_TRAIN / BATCH_SIZE),\n",
    "            epochs=pretraining_epochs,\n",
    "            validation_data=generators['val'],\n",
    "            validation_steps=np.ceil(N_VAL / BATCH_SIZE),\n",
    "            callbacks=callbacks,\n",
    "            workers=4,\n",
    "            max_queue_size=5)\n",
    "\n",
    "    metrics = model.evaluate_generator(generators['test'], \n",
    "                                       steps=np.ceil(N_TEST / BATCH_SIZE),\n",
    "                                       max_queue_size=5, workers=4)    \n",
    "    print(metrics)\n",
    "    \n",
    "    last_epoch = pretraining_epochs\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "post_training = True\n",
    "post_training_epochs = 20\n",
    "if post_training:\n",
    "    # unfreeze the model\n",
    "    # unfreeze(model, n_blocks='all')\n",
    "    # freeze 3 blocks\n",
    "    # freeze(model, n_blocks=3)\n",
    "\n",
    "    # we need to recompile the model for these modifications to take effect\n",
    "    # we use SGD with a low learning rate\n",
    "    from keras.optimizers import SGD\n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), \n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "    # alongside the top Dense layers\n",
    "    model.fit_generator(\n",
    "            generators['train'],\n",
    "            steps_per_epoch=np.ceil(N_TRAIN / BATCH_SIZE),\n",
    "            epochs=last_epoch + post_training_epochs,\n",
    "            validation_data=generators['val'],\n",
    "            validation_steps=np.ceil(N_VAL / BATCH_SIZE),\n",
    "            callbacks=callbacks, initial_epoch=last_epoch,\n",
    "            workers=4, max_queue_size=5)\n",
    "\n",
    "    metrics = model.evaluate_generator(generators['test'], \n",
    "                                       steps=np.ceil(N_TEST / BATCH_SIZE), \n",
    "                                       workers=4, max_queue_size=5)\n",
    "\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate_generator(generators['test'], \n",
    "                                   steps=np.ceil(N_TEST / BATCH_SIZE), \n",
    "                                   max_queue_size=5, workers=4)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tensorflow_gpu():\n",
    "    import tensorflow as tf\n",
    "    with tf.device('/gpu:0'):\n",
    "        a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "        b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "        c = tf.matmul(a, b)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print (sess.run(c))\n",
    "\n",
    "check_tensorflow_gpu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
