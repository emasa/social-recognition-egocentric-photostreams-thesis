{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_notebook(fix_python_path=True, reduce_margins=True, plot_inline=True):\n",
    "    if reduce_margins:\n",
    "        # Reduce side margins of the notebook\n",
    "        from IPython.core.display import display, HTML\n",
    "        display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "    if fix_python_path:\n",
    "        # add egosocial to the python path\n",
    "        import os, sys\n",
    "        sys.path.extend([os.path.dirname(os.path.abspath('.'))])\n",
    "\n",
    "    if plot_inline:\n",
    "        # Plots inside cells\n",
    "        %matplotlib inline\n",
    "    \n",
    "    global __file__\n",
    "    __file__ = 'Notebook'\n",
    "\n",
    "setup_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import argparse\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "import egosocial\n",
    "import egosocial.config\n",
    "from egosocial.utils.filesystem import create_directory\n",
    "from egosocial.utils.filesystem import check_directory\n",
    "from egosocial.utils.keras.backend import limit_gpu_allocation_tensorflow\n",
    "from egosocial.utils.keras.processing import TimeSeriesDataGenerator\n",
    "from egosocial.utils.logging import setup_logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit GPU memory allocation with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_memory = False\n",
    "if limit_memory and K.backend() == 'tensorflow':\n",
    "    memory_ratio = 0.6\n",
    "    limit_gpu_allocation_tensorflow(memory_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def main(*fake_args):\n",
    "    entry_msg = 'Extract features for egosocial photo-streams.'\n",
    "    parser = argparse.ArgumentParser(description=entry_msg)\n",
    "\n",
    "    parser.add_argument('--dataset_path', required=True,\n",
    "                        help='Path to file containing the input data and labels information merged.')\n",
    "\n",
    "    parser.add_argument('--features_dir', required=True,\n",
    "                        help='Directory where the extracted features are stored.')\n",
    "        \n",
    "    if not os.path.isdir(egosocial.config.TMP_DIR):\n",
    "        os.mkdir(egosocial.config.TMP_DIR)\n",
    "\n",
    "    setup_logging(egosocial.config.LOGGING_CONFIG,\n",
    "                  log_dir=egosocial.config.LOGS_DIR)\n",
    "    \n",
    "    # TODO: implement correctly\n",
    "    args = parser.parse_args(*fake_args)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.join(egosocial.config.TMP_DIR, 'egocentric', 'datasets')\n",
    "\n",
    "args = [\n",
    "    \"--dataset_path\", os.path.join(BASE_DIR, 'merged_dataset.json'),\n",
    "    \"--features_dir\", os.path.join(BASE_DIR, 'extracted_features'),\n",
    "]\n",
    "\n",
    "conf = main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_defition(dataset_path):\n",
    "    with open(dataset_path, 'r') as json_file:\n",
    "        dataset_def = json.load(json_file)\n",
    "\n",
    "    # flatten the segments structure\n",
    "    samples = pd.DataFrame(list(itertools.chain(*dataset_def)))\n",
    "    return samples\n",
    "\n",
    "def load_features(features_path, data_frames):\n",
    "    features = np.load(features_path)\n",
    "    \n",
    "    sequences_info = data_frames.groupby(['split', 'segment_id', 'group_id'])\n",
    "    \n",
    "    feature_sequences = []\n",
    "    for seq_id, group in sequences_info:\n",
    "        feature_seq = []\n",
    "\n",
    "        for frame_idx in group.index:\n",
    "            feature_seq.append(features[frame_idx])\n",
    "\n",
    "        feature_sequences.append(feature_seq)\n",
    "    \n",
    "    return feature_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main  class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset definition\n",
    "frames = load_dataset_defition(conf.dataset_path)\n",
    "\n",
    "# filter labels with few samples\n",
    "valid_frames_idx = ~np.isin(frames['relation_label'], ['siblings', 'teacher-student'])\n",
    "valid_frames = frames[valid_frames_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load features\n",
    "features_path = os.path.join(conf.features_dir, 'activity.npy')\n",
    "feature_sequences = load_features(features_path, valid_frames)\n",
    "max_timesteps = max(len(seq) for seq in feature_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = TimeSeriesDataGenerator(fancy_pca=True)\n",
    "gen.fit(feature_sequences)\n",
    "flow_gen = gen.flow(feature_sequences, maxlen=max_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(flow_gen).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
